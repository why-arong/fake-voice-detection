{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNv/6ew9RL07voXpDnKlK+5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/why-arong/fake-voice-detection/blob/mel-resnet/merged_mel_resnet_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare data"
      ],
      "metadata": {
        "id": "ZumbPFlx_YWT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPWHF7RdVfJA",
        "outputId": "f153db80-6110-46dc-9b78-ba3fa7f71821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-05 14:11:45--  https://drive.usercontent.google.com/download?id=1HLBDBTnrLvVdqXxMQTDJyTUf5ryBqcxD&export=download&authuser=1&confirm=t\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 74.125.130.132, 2404:6800:4003:c01::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|74.125.130.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3313752771 (3.1G) [application/octet-stream]\n",
            "Saving to: ‘open.zip’\n",
            "\n",
            "open.zip            100%[===================>]   3.09G  90.7MB/s    in 49s     \n",
            "\n",
            "2024-07-05 14:12:34 (65.1 MB/s) - ‘open.zip’ saved [3313752771/3313752771]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://drive.usercontent.google.com/download?id=1HLBDBTnrLvVdqXxMQTDJyTUf5ryBqcxD&export=download&authuser=1&confirm=t' -O open.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q open.zip"
      ],
      "metadata": {
        "id": "n1aNdg46V9pL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries and setting"
      ],
      "metadata": {
        "id": "PViVm1pz_b-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "fw_Vdb-9dkGX"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SR = 32000\n",
        "SEED = 1\n",
        "BATCH = 32\n",
        "EPOCH = 10\n",
        "LR = 1e-4"
      ],
      "metadata": {
        "id": "NdrOQCZOGwu5"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(SEED)"
      ],
      "metadata": {
        "id": "l76-i46ItR2H"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define dataset and augmetation pipeline"
      ],
      "metadata": {
        "id": "3YcNOy2L_wbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_fixed_length(audio, fixed_len):\n",
        "    _, length = audio.size()\n",
        "\n",
        "    if length < fixed_len:\n",
        "        to_pad = fixed_len - length\n",
        "        left_pad = torch.randint(0, to_pad + 1, (1,)).item()\n",
        "        right_pad = to_pad - left_pad\n",
        "        audio = torch.nn.functional.pad(audio, (left_pad, right_pad), mode='constant', value=0)\n",
        "    else:\n",
        "        start = torch.randint(0, length - fixed_len + 1, (1,)).item()\n",
        "        audio = audio[:, start:start + fixed_len]\n",
        "\n",
        "    return audio\n",
        "\n",
        "\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, file_paths, labels, fixed_len=64000):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.fixed_len = fixed_len\n",
        "        self.length = len(file_paths)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        rand_val = random.random()\n",
        "\n",
        "        if rand_val <= 0.25:\n",
        "            wave = torch.zeros(1, self.fixed_len)\n",
        "            merged_label = (0, 0)\n",
        "\n",
        "        elif rand_val <= 0.5:\n",
        "            path, label = self.file_paths[idx], self.labels[idx]\n",
        "            wave, _ = torchaudio.load(path)\n",
        "            wave = convert_to_fixed_length(wave, self.fixed_len)\n",
        "            merged_label = (0, 1) if label else (1, 0)\n",
        "\n",
        "        else:\n",
        "            rand_idx = np.random.randint(0, self.length)\n",
        "            path1, label1 = self.file_paths[idx], self.labels[idx]\n",
        "            path2, label2 = self.file_paths[rand_idx], self.labels[rand_idx]\n",
        "\n",
        "            wave1, _ = torchaudio.load(path1)\n",
        "            wave2, _ = torchaudio.load(path2)\n",
        "\n",
        "            wave1 = convert_to_fixed_length(wave1, self.fixed_len)\n",
        "            wave2 = convert_to_fixed_length(wave2, self.fixed_len)\n",
        "\n",
        "            wave = (wave1 + wave2) / 2\n",
        "            merged_label = (int(label1 == 0 or label2 == 0), int(label1 == 1 or label2 == 1))\n",
        "\n",
        "        label = torch.tensor(merged_label).float()\n",
        "        return wave, label"
      ],
      "metadata": {
        "id": "Hn6tjLg4Hw8j"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioPipeline(nn.Module):\n",
        "    def __init__(self, on_train=True, noise_level=0.1, shape=(128, 128), fixed_len=64000):\n",
        "        super().__init__()\n",
        "        self.on_train = on_train\n",
        "        self.noise_level = noise_level\n",
        "\n",
        "        self.spec = T.MelSpectrogram(\n",
        "            sample_rate=SR,\n",
        "            n_fft=2048,\n",
        "            win_length=1024,\n",
        "            hop_length=fixed_len // shape[1] + 1,\n",
        "            n_mels=shape[0]\n",
        "        )\n",
        "        self.to_db = T.AmplitudeToDB()\n",
        "        self.spec_aug = nn.Sequential(\n",
        "            T.FrequencyMasking(32),\n",
        "            T.TimeMasking(12),\n",
        "            T.TimeMasking(12),\n",
        "        )\n",
        "\n",
        "    def forward(self, wave):\n",
        "        with torch.no_grad():\n",
        "            if self.on_train:\n",
        "                noise = torch.randn_like(wave) * self.noise_level\n",
        "                wave = wave + noise\n",
        "\n",
        "            spec = self.spec(wave)\n",
        "            spec = self.to_db(spec)\n",
        "\n",
        "            if self.on_train:\n",
        "                spec = self.spec_aug(spec)\n",
        "\n",
        "            spec = self.normalize(spec)\n",
        "        return spec\n",
        "\n",
        "    def normalize(self, spec, epsilon=1e-6):\n",
        "        mean = spec.mean(dim=[2, 3], keepdim=True)\n",
        "        std = spec.std(dim=[2, 3], keepdim=True)\n",
        "        return (spec - mean) / (std + epsilon)\n",
        "\n",
        "    def train(self):\n",
        "        self.on_train = True\n",
        "\n",
        "    def eval(self):\n",
        "        self.on_train = False"
      ],
      "metadata": {
        "id": "FD15bZBP0Q0J"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "train[\"label\"] = train[\"label\"].apply(lambda x: 1 if x == \"real\" else 0)\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YZ7aeiCBM618",
        "outputId": "46c41a29-2930-4841-b77d-09031f540c7c"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id                  path  label\n",
              "0  RUNQPNJF  ./train/RUNQPNJF.ogg      1\n",
              "1  JFAWUOGJ  ./train/JFAWUOGJ.ogg      0\n",
              "2  RDKEKEVX  ./train/RDKEKEVX.ogg      1\n",
              "3  QYHJDOFK  ./train/QYHJDOFK.ogg      1\n",
              "4  RSPQNHAO  ./train/RSPQNHAO.ogg      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad841120-f494-4a34-98f8-2769c76ab598\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RUNQPNJF</td>\n",
              "      <td>./train/RUNQPNJF.ogg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>JFAWUOGJ</td>\n",
              "      <td>./train/JFAWUOGJ.ogg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RDKEKEVX</td>\n",
              "      <td>./train/RDKEKEVX.ogg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>QYHJDOFK</td>\n",
              "      <td>./train/QYHJDOFK.ogg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RSPQNHAO</td>\n",
              "      <td>./train/RSPQNHAO.ogg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad841120-f494-4a34-98f8-2769c76ab598')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad841120-f494-4a34-98f8-2769c76ab598 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad841120-f494-4a34-98f8-2769c76ab598');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-74b52e7c-0b84-4cf6-b89a-fe671bd43023\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74b52e7c-0b84-4cf6-b89a-fe671bd43023')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-74b52e7c-0b84-4cf6-b89a-fe671bd43023 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train",
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 55438,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 55438,\n        \"samples\": [\n          \"PUOXNOKJ\",\n          \"GXOIPDJP\",\n          \"FOEQKPPR\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 55438,\n        \"samples\": [\n          \"./train/PUOXNOKJ.ogg\",\n          \"./train/GXOIPDJP.ogg\",\n          \"./train/FOEQKPPR.ogg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_paths, valid_paths, train_labels, valid_labels = train_test_split(\n",
        "    train[\"path\"].values, train[\"label\"].values, test_size=0.2, stratify=train[\"label\"]\n",
        ")\n",
        "\n",
        "train_dataset = AudioDataset(train_paths, train_labels)\n",
        "valid_dataset = AudioDataset(valid_paths, valid_labels)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "audio_pipeline = AudioPipeline().to(device)"
      ],
      "metadata": {
        "id": "TMubx8kTNsFH"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define model"
      ],
      "metadata": {
        "id": "CB1330cq_8ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = ConvBlock(in_channels, out_channels, stride=stride)\n",
        "        self.conv2 = ConvBlock(out_channels, out_channels)\n",
        "\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = self.shortcut(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x + shortcut\n",
        "        x = self.relu(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2_Sn6C5JO6AX"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioClassifier(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = ConvBlock(1, 16)\n",
        "        self.res1 = ResBlock(16, 16)\n",
        "        self.res2 = ResBlock(16, 32, stride=2)\n",
        "        self.res3 = ResBlock(32, 32)\n",
        "        self.res4 = ResBlock(32, 64, stride=2)\n",
        "        self.res5 = ResBlock(64, 64)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc1 = nn.Linear(64, 256)\n",
        "        self.fc2 = nn.Linear(256, n_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.res1(x)\n",
        "        x = self.res2(x)\n",
        "        x = self.res3(x)\n",
        "        x = self.res4(x)\n",
        "        x = self.res5(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Gxic48kdO7gT"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AudioClassifier(2).to(device)\n",
        "\n",
        "summary(model, input_size=(1, 128, 128))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2bUofVLO-DX",
        "outputId": "204ea698-f0ea-4832-a2f8-0d7a6972ef66"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 128, 128]             160\n",
            "       BatchNorm2d-2         [-1, 16, 128, 128]              32\n",
            "              ReLU-3         [-1, 16, 128, 128]               0\n",
            "         ConvBlock-4         [-1, 16, 128, 128]               0\n",
            "          Identity-5         [-1, 16, 128, 128]               0\n",
            "            Conv2d-6         [-1, 16, 128, 128]           2,320\n",
            "       BatchNorm2d-7         [-1, 16, 128, 128]              32\n",
            "              ReLU-8         [-1, 16, 128, 128]               0\n",
            "         ConvBlock-9         [-1, 16, 128, 128]               0\n",
            "           Conv2d-10         [-1, 16, 128, 128]           2,320\n",
            "      BatchNorm2d-11         [-1, 16, 128, 128]              32\n",
            "             ReLU-12         [-1, 16, 128, 128]               0\n",
            "        ConvBlock-13         [-1, 16, 128, 128]               0\n",
            "             ReLU-14         [-1, 16, 128, 128]               0\n",
            "         ResBlock-15         [-1, 16, 128, 128]               0\n",
            "           Conv2d-16           [-1, 32, 64, 64]             512\n",
            "      BatchNorm2d-17           [-1, 32, 64, 64]              64\n",
            "           Conv2d-18           [-1, 32, 64, 64]           4,640\n",
            "      BatchNorm2d-19           [-1, 32, 64, 64]              64\n",
            "             ReLU-20           [-1, 32, 64, 64]               0\n",
            "        ConvBlock-21           [-1, 32, 64, 64]               0\n",
            "           Conv2d-22           [-1, 32, 64, 64]           9,248\n",
            "      BatchNorm2d-23           [-1, 32, 64, 64]              64\n",
            "             ReLU-24           [-1, 32, 64, 64]               0\n",
            "        ConvBlock-25           [-1, 32, 64, 64]               0\n",
            "             ReLU-26           [-1, 32, 64, 64]               0\n",
            "         ResBlock-27           [-1, 32, 64, 64]               0\n",
            "         Identity-28           [-1, 32, 64, 64]               0\n",
            "           Conv2d-29           [-1, 32, 64, 64]           9,248\n",
            "      BatchNorm2d-30           [-1, 32, 64, 64]              64\n",
            "             ReLU-31           [-1, 32, 64, 64]               0\n",
            "        ConvBlock-32           [-1, 32, 64, 64]               0\n",
            "           Conv2d-33           [-1, 32, 64, 64]           9,248\n",
            "      BatchNorm2d-34           [-1, 32, 64, 64]              64\n",
            "             ReLU-35           [-1, 32, 64, 64]               0\n",
            "        ConvBlock-36           [-1, 32, 64, 64]               0\n",
            "             ReLU-37           [-1, 32, 64, 64]               0\n",
            "         ResBlock-38           [-1, 32, 64, 64]               0\n",
            "           Conv2d-39           [-1, 64, 32, 32]           2,048\n",
            "      BatchNorm2d-40           [-1, 64, 32, 32]             128\n",
            "           Conv2d-41           [-1, 64, 32, 32]          18,496\n",
            "      BatchNorm2d-42           [-1, 64, 32, 32]             128\n",
            "             ReLU-43           [-1, 64, 32, 32]               0\n",
            "        ConvBlock-44           [-1, 64, 32, 32]               0\n",
            "           Conv2d-45           [-1, 64, 32, 32]          36,928\n",
            "      BatchNorm2d-46           [-1, 64, 32, 32]             128\n",
            "             ReLU-47           [-1, 64, 32, 32]               0\n",
            "        ConvBlock-48           [-1, 64, 32, 32]               0\n",
            "             ReLU-49           [-1, 64, 32, 32]               0\n",
            "         ResBlock-50           [-1, 64, 32, 32]               0\n",
            "         Identity-51           [-1, 64, 32, 32]               0\n",
            "           Conv2d-52           [-1, 64, 32, 32]          36,928\n",
            "      BatchNorm2d-53           [-1, 64, 32, 32]             128\n",
            "             ReLU-54           [-1, 64, 32, 32]               0\n",
            "        ConvBlock-55           [-1, 64, 32, 32]               0\n",
            "           Conv2d-56           [-1, 64, 32, 32]          36,928\n",
            "      BatchNorm2d-57           [-1, 64, 32, 32]             128\n",
            "             ReLU-58           [-1, 64, 32, 32]               0\n",
            "        ConvBlock-59           [-1, 64, 32, 32]               0\n",
            "             ReLU-60           [-1, 64, 32, 32]               0\n",
            "         ResBlock-61           [-1, 64, 32, 32]               0\n",
            "AdaptiveAvgPool2d-62             [-1, 64, 1, 1]               0\n",
            "           Linear-63                  [-1, 256]          16,640\n",
            "             ReLU-64                  [-1, 256]               0\n",
            "           Linear-65                    [-1, 2]             514\n",
            "================================================================\n",
            "Total params: 187,234\n",
            "Trainable params: 187,234\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.06\n",
            "Forward/backward pass size (MB): 64.50\n",
            "Params size (MB): 0.71\n",
            "Estimated Total Size (MB): 65.28\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "0x5Hdd63AFip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoch(model, dataloader, pipeline, optimizer, criterion, train=True):\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "    correct = 0\n",
        "\n",
        "    if train:\n",
        "        model.train()\n",
        "        pipeline.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "        pipeline.eval()\n",
        "\n",
        "    for waves, labels in tqdm(dataloader, desc=\"Training\" if train else \"Evaluating\"):\n",
        "        waves = waves.to(device)\n",
        "        specs = audio_pipeline(waves)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(specs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        count += len(labels) * 2\n",
        "        correct += ((outputs > 0).float() == labels).sum().item()\n",
        "\n",
        "    return total_loss / count, correct / count"
      ],
      "metadata": {
        "id": "j5epqFg0R3x9"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "valid_losses = []\n",
        "valid_accuracies = []\n",
        "\n",
        "best_accuracy = 0\n",
        "best_model = None\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "\n",
        "    train_loss, train_accuracy = run_epoch(model, train_dataloader, audio_pipeline, optimizer, criterion, train=True)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.8f}\")\n",
        "    print(f\"Train Accuracy: {train_accuracy:.8f}\")\n",
        "\n",
        "    valid_loss, valid_accuracy = run_epoch(model, valid_dataloader, audio_pipeline, optimizer, criterion, train=False)\n",
        "    valid_losses.append(valid_loss)\n",
        "    valid_accuracies.append(valid_accuracy)\n",
        "\n",
        "    print(f\"Test Loss: {valid_loss:.8f}\")\n",
        "    print(f\"Test Accuracy: {valid_accuracy:.8f}\")\n",
        "\n",
        "    if valid_accuracy > best_accuracy:\n",
        "        best_accuracy = valid_accuracy\n",
        "        best_model = model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "id": "FrCFzyNPPoYw",
        "outputId": "45264bd1-15a0-4fc3-fc1a-b49aa7bdc3e3"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1386/1386 [07:23<00:00,  3.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.00628956\n",
            "Train Accuracy: 0.80489290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 347/347 [01:26<00:00,  3.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.01349071\n",
            "Test Accuracy: 0.61918290\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1386/1386 [07:20<00:00,  3.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.00440055\n",
            "Train Accuracy: 0.87418264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 347/347 [01:29<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.02719754\n",
            "Test Accuracy: 0.60466270\n",
            "Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1386/1386 [07:29<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.00393953\n",
            "Train Accuracy: 0.88864713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 347/347 [01:26<00:00,  4.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.02694301\n",
            "Test Accuracy: 0.66224747\n",
            "Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1386/1386 [07:29<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.00360815\n",
            "Train Accuracy: 0.89972943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 347/347 [01:30<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.03566043\n",
            "Test Accuracy: 0.38974567\n",
            "Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1386/1386 [07:27<00:00,  3.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.00349705\n",
            "Train Accuracy: 0.90178129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 347/347 [01:28<00:00,  3.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.03189618\n",
            "Test Accuracy: 0.38271104\n",
            "Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  42%|████▏     | 578/1386 [03:06<04:20,  3.10it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-abf661a00d10>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-125-56c971a14639>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(model, dataloader, pipeline, optimizer, criterion, train)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_range = range(EPOCH)\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, train_losses, label='Train Loss')\n",
        "plt.plot(epochs_range, valid_losses, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, train_accuracies, label='Train Accuracy')\n",
        "plt.plot(epochs_range, valid_accuracies, label='Test Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hPeWDBmEcV09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(best_model.state_dict(), \"merged_mel_resnet_v3.pth\")"
      ],
      "metadata": {
        "id": "t7vY2lFNNcid"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "whw07Xzx8d5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestAudioDataset(Dataset):\n",
        "    def __init__(self, file_paths, fixed_len=64000):\n",
        "        self.file_paths = file_paths\n",
        "        self.fixed_len = fixed_len\n",
        "        self.length = len(file_paths)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        wave, _ = torchaudio.load(self.file_paths[index])\n",
        "\n",
        "        start_idx = int(1.5 * SR)\n",
        "        end_idx = int(3.5 * SR)\n",
        "        wave = wave[:, start_idx:end_idx]\n",
        "        return wave"
      ],
      "metadata": {
        "id": "jJBWuCHgfyFo"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(\"test.csv\")\n",
        "test_dataset = TestAudioDataset(test[\"path\"].values)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "8Ibnjek7ii6m"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.eval()\n",
        "audio_pipeline.eval()\n",
        "preds = []\n",
        "\n",
        "for waves in tqdm(test_dataloader):\n",
        "    specs = audio_pipeline(waves.to(device))\n",
        "    outputs = best_model(data)\n",
        "    pred = F.sigmoid(outputs).detach().cpu().numpy()\n",
        "    preds += pred.tolist()"
      ],
      "metadata": {
        "id": "Zz76PZ5viveo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv(\"sample_submission.csv\")\n",
        "submit.iloc[:, 1:] = preds\n",
        "submit.to_csv(\"merged_mel_resnet_v2_max.csv\", index=False)"
      ],
      "metadata": {
        "id": "LWGN5oV2mDDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit.head()"
      ],
      "metadata": {
        "id": "wIeKg3M9zEYB",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Distribution of Fake\")\n",
        "plt.hist(submit[\"fake\"], bins=20)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Distribution of Real\")\n",
        "plt.hist(submit[\"real\"], bins=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XYsUmtuX0UDP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}