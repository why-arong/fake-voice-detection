{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOJm14EMlZF/PGVYyN2WkHL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/why-arong/fake-voice-detection/blob/mel-resnet/ssl_unlabeled_mel_resnet_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare data"
      ],
      "metadata": {
        "id": "ZumbPFlx_YWT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPWHF7RdVfJA"
      },
      "outputs": [],
      "source": [
        "!wget 'https://drive.usercontent.google.com/download?id=1HLBDBTnrLvVdqXxMQTDJyTUf5ryBqcxD&export=download&authuser=1&confirm=t' -O open.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q open.zip"
      ],
      "metadata": {
        "id": "n1aNdg46V9pL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries and setting"
      ],
      "metadata": {
        "id": "PViVm1pz_b-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device"
      ],
      "metadata": {
        "id": "fw_Vdb-9dkGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SR = 32000\n",
        "SEED = 1"
      ],
      "metadata": {
        "id": "NdrOQCZOGwu5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(SEED)"
      ],
      "metadata": {
        "id": "l76-i46ItR2H"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define dataset and augmetation pipeline"
      ],
      "metadata": {
        "id": "3YcNOy2L_wbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_fixed_length(audio, fixed_len):\n",
        "    _, length = audio.size()\n",
        "\n",
        "    if length < fixed_len:\n",
        "        to_pad = fixed_len - length\n",
        "        left_pad = torch.randint(0, to_pad + 1, (1,)).item()\n",
        "        right_pad = to_pad - left_pad\n",
        "        audio = torch.nn.functional.pad(audio, (left_pad, right_pad), mode='constant', value=0)\n",
        "    else:\n",
        "        start = torch.randint(0, length - fixed_len + 1, (1,)).item()\n",
        "        audio = audio[:, start:start + fixed_len]\n",
        "\n",
        "    return audio\n",
        "\n",
        "\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, data_paths, labels, unlabeled_paths, fixed_len=SR*4):\n",
        "        self.data_paths = data_paths\n",
        "        self.labels = labels\n",
        "        self.unlabeled_paths = unlabeled_paths\n",
        "        self.fixed_len = fixed_len\n",
        "\n",
        "        self.data_length = len(data_paths)\n",
        "        self.unlabeled_length = len(unlabeled_paths)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        rand_val = random.random()\n",
        "        is_gt = (True, True)\n",
        "\n",
        "        if rand_val <= 0.15:\n",
        "            wave = torch.zeros(1, self.fixed_len)\n",
        "            merged_label = (0, 0)\n",
        "\n",
        "        elif rand_val <= 0.3:\n",
        "            path, label = self.data_paths[idx], self.labels[idx]\n",
        "            wave, _ = torchaudio.load(path)\n",
        "            wave = convert_to_fixed_length(wave, self.fixed_len)\n",
        "            merged_label = (0, 1) if label else (1, 0)\n",
        "\n",
        "        elif rand_val <= 0.6:\n",
        "            rand_idx = np.random.randint(0, self.data_length)\n",
        "            path1, label1 = self.data_paths[idx], self.labels[idx]\n",
        "            path2, label2 = self.data_paths[rand_idx], self.labels[rand_idx]\n",
        "\n",
        "            wave1, _ = torchaudio.load(path1)\n",
        "            wave2, _ = torchaudio.load(path2)\n",
        "\n",
        "            wave1 = convert_to_fixed_length(wave1, self.fixed_len)\n",
        "            wave2 = convert_to_fixed_length(wave2, self.fixed_len)\n",
        "\n",
        "            wave = (wave1 + wave2) / 2\n",
        "            merged_label = (int(label1 == 0 or label2 == 0), int(label1 == 1 or label2 == 1))\n",
        "\n",
        "        else:\n",
        "            rand_idx = np.random.randint(0, self.unlabeled_length)\n",
        "            path1, label = self.data_paths[idx], self.labels[idx]\n",
        "            path2 = self.unlabeled_paths[rand_idx]\n",
        "\n",
        "            wave1, _ = torchaudio.load(path1)\n",
        "            wave2, _ = torchaudio.load(path2)\n",
        "\n",
        "            wave1 = convert_to_fixed_length(wave1, self.fixed_len)\n",
        "            wave2 = convert_to_fixed_length(wave2, self.fixed_len)\n",
        "\n",
        "            wave = (wave1 + wave2) / 2\n",
        "            merged_label = (1, 1)\n",
        "            is_gt = (False, True) if label else (True, False)\n",
        "\n",
        "        label = torch.tensor(merged_label).float()\n",
        "        is_gt = torch.tensor(is_gt).bool()\n",
        "        return wave, label, is_gt"
      ],
      "metadata": {
        "id": "Hn6tjLg4Hw8j"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioPipeline(nn.Module):\n",
        "    def __init__(self, on_train=True, noise_level=0.1):\n",
        "        super().__init__()\n",
        "        self.on_train = on_train\n",
        "        self.noise_level = noise_level\n",
        "\n",
        "        self.spec_250 = self.create_spec(250)\n",
        "        self.spec_500 = self.create_spec(500)\n",
        "        self.spec_750 = self.create_spec(750)\n",
        "        self.spec_1000 = self.create_spec(1000)\n",
        "\n",
        "        self.spec_aug = nn.Sequential(\n",
        "            T.FrequencyMasking(20),\n",
        "            T.TimeMasking(10),\n",
        "            T.TimeMasking(10),\n",
        "        )\n",
        "\n",
        "    def create_spec(self, win_length):\n",
        "        return nn.Sequential(\n",
        "            T.MelSpectrogram(\n",
        "                sample_rate=SR,\n",
        "                n_fft=2048,\n",
        "                win_length=win_length,\n",
        "                hop_length=500,\n",
        "                n_mels=128\n",
        "            ),\n",
        "            T.AmplitudeToDB()\n",
        "        )\n",
        "\n",
        "    def forward(self, wave):\n",
        "        with torch.no_grad():\n",
        "            if self.on_train:\n",
        "                noise = torch.randn_like(wave) * self.noise_level\n",
        "                wave = wave + noise\n",
        "\n",
        "            spec0 = self.spec_250(wave)\n",
        "            spec1 = self.spec_500(wave)\n",
        "            spec2 = self.spec_750(wave)\n",
        "            spec3 = self.spec_1000(wave)\n",
        "            specs = torch.cat([spec0, spec1, spec2, spec3], dim=1)[:, :, :, :-1]\n",
        "\n",
        "            if self.on_train:\n",
        "                specs = self.spec_aug(specs)\n",
        "\n",
        "            specs = self.normalize(specs)\n",
        "        return specs\n",
        "\n",
        "    def normalize(self, spec, epsilon=1e-6):\n",
        "        mean = spec.mean(dim=[2, 3], keepdim=True)\n",
        "        std = spec.std(dim=[2, 3], keepdim=True)\n",
        "        return (spec - mean) / (std + epsilon)\n",
        "\n",
        "    def train(self):\n",
        "        self.on_train = True\n",
        "\n",
        "    def eval(self):\n",
        "        self.on_train = False"
      ],
      "metadata": {
        "id": "FD15bZBP0Q0J"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "train[\"label\"] = train[\"label\"].apply(lambda x: 1 if x == \"real\" else 0)\n",
        "train.head()"
      ],
      "metadata": {
        "id": "YZ7aeiCBM618"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unlabeled_folder = \"./unlabeled_data\"\n",
        "unlabeled_paths = [os.path.join(unlabeled_folder, file_path) for file_path in os.listdir(unlabeled_folder)]\n",
        "unlabeled_paths[:5]"
      ],
      "metadata": {
        "id": "iE46Qk7bym5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_paths, valid_paths, train_labels, valid_labels = train_test_split(\n",
        "    train[\"path\"].values, train[\"label\"].values, test_size=0.2, stratify=train[\"label\"]\n",
        ")\n",
        "\n",
        "train_dataset = AudioDataset(train_paths, train_labels, unlabeled_paths)\n",
        "valid_dataset = AudioDataset(valid_paths, valid_labels, unlabeled_paths)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "audio_pipeline = AudioPipeline().to(device)"
      ],
      "metadata": {
        "id": "TMubx8kTNsFH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define model"
      ],
      "metadata": {
        "id": "CB1330cq_8ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = ConvBlock(in_channels, out_channels, stride=stride)\n",
        "        self.conv2 = ConvBlock(out_channels, out_channels)\n",
        "\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = self.shortcut(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x + shortcut\n",
        "        x = self.relu(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2_Sn6C5JO6AX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioClassifier(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = ConvBlock(4, 16)\n",
        "        self.res1 = ResBlock(16, 16)\n",
        "        self.res2 = ResBlock(16, 32, stride=2)\n",
        "        self.res3 = ResBlock(32, 32)\n",
        "        self.res4 = ResBlock(32, 64, stride=2)\n",
        "        self.res5 = ResBlock(64, 64)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc1 = nn.Linear(64, 256)\n",
        "        self.fc2 = nn.Linear(256, n_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.res1(x)\n",
        "        x = self.res2(x)\n",
        "        x = self.res3(x)\n",
        "        x = self.res4(x)\n",
        "        x = self.res5(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Gxic48kdO7gT"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AudioClassifier(2).to(device)\n",
        "\n",
        "summary(model, input_size=(4, 128, 256))"
      ],
      "metadata": {
        "id": "J2bUofVLO-DX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "0x5Hdd63AFip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoch(model, dataloader, pipeline, optimizer, train=True):\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    if train:\n",
        "        model.train()\n",
        "        # pipeline.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "        # pipeline.eval()\n",
        "\n",
        "    for waves, labels, is_gt in tqdm(dataloader, desc=\"Training\" if train else \"Evaluating\"):\n",
        "        waves = waves.to(device)\n",
        "        specs = audio_pipeline(waves)\n",
        "        labels = labels.to(device)\n",
        "        is_gt = is_gt.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(specs)\n",
        "        loss = F.binary_cross_entropy_with_logits(outputs, labels, reduction=\"none\")\n",
        "        loss = torch.sum(loss * is_gt) / torch.sum(is_gt)\n",
        "\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        count += len(labels) * 2\n",
        "\n",
        "    return total_loss / count"
      ],
      "metadata": {
        "id": "j5epqFg0R3x9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH = 32\n",
        "EPOCH = 50\n",
        "LR = 1e-4\n",
        "WD = 1e-4\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
        "audio_pipeline.eval()"
      ],
      "metadata": {
        "id": "RbSGvtiFL6w4"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "best_loss = float(\"inf\")\n",
        "best_model = None\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "\n",
        "    train_loss = run_epoch(model, train_dataloader, audio_pipeline, optimizer, train=True)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.8f}\")\n",
        "\n",
        "    valid_loss = run_epoch(model, valid_dataloader, audio_pipeline, optimizer, train=False)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f\"Test Loss: {valid_loss:.8f}\")\n",
        "\n",
        "    if valid_loss < best_loss:\n",
        "        best_loss = valid_loss\n",
        "        best_model = model"
      ],
      "metadata": {
        "id": "FrCFzyNPPoYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_range = range(EPOCH)\n",
        "plt.figure(figsize=(6, 5))\n",
        "\n",
        "plt.plot(epochs_range, train_losses, label='Train Loss')\n",
        "plt.plot(epochs_range, valid_losses, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hPeWDBmEcV09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(best_model.state_dict(), \"ssl_unlabeled_mel_resnet_v3_50ep.pth\")"
      ],
      "metadata": {
        "id": "t7vY2lFNNcid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "whw07Xzx8d5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestAudioDataset(Dataset):\n",
        "    def __init__(self, file_paths):\n",
        "        self.file_paths = file_paths\n",
        "        self.length = len(file_paths)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        wave, _ = torchaudio.load(self.file_paths[index])\n",
        "\n",
        "        start_idx = int(0.5 * SR)\n",
        "        end_idx = int(4.5 * SR)\n",
        "        wave = wave[:, start_idx:end_idx]\n",
        "        return wave"
      ],
      "metadata": {
        "id": "jJBWuCHgfyFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(\"test.csv\")\n",
        "test_dataset = TestAudioDataset(test[\"path\"].values)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "8Ibnjek7ii6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.eval()\n",
        "audio_pipeline.eval()\n",
        "preds = []\n",
        "\n",
        "for waves in tqdm(test_dataloader):\n",
        "    specs = audio_pipeline(waves.to(device))\n",
        "    outputs = best_model(specs)\n",
        "    pred = F.sigmoid(outputs).detach().cpu().numpy()\n",
        "    preds += pred.tolist()"
      ],
      "metadata": {
        "id": "Zz76PZ5viveo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv(\"sample_submission.csv\")\n",
        "submit.iloc[:, 1:] = preds\n",
        "submit.to_csv(\"ssl_unlabeled_mel_resnet_v3_50ep.csv\", index=False)"
      ],
      "metadata": {
        "id": "LWGN5oV2mDDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit.head()"
      ],
      "metadata": {
        "id": "wIeKg3M9zEYB",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f7182da5-73a1-4b9e-dbfe-0a4b15d73f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id      fake      real\n",
              "0  TEST_00000  0.924100  0.554286\n",
              "1  TEST_00001  0.954350  0.535958\n",
              "2  TEST_00002  0.973309  0.465455\n",
              "3  TEST_00003  0.999197  0.479815\n",
              "4  TEST_00004  0.838927  0.738077"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c79ab3f9-e181-4a6b-8788-04033beb5e67\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>fake</th>\n",
              "      <th>real</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TEST_00000</td>\n",
              "      <td>0.924100</td>\n",
              "      <td>0.554286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TEST_00001</td>\n",
              "      <td>0.954350</td>\n",
              "      <td>0.535958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEST_00002</td>\n",
              "      <td>0.973309</td>\n",
              "      <td>0.465455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEST_00003</td>\n",
              "      <td>0.999197</td>\n",
              "      <td>0.479815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEST_00004</td>\n",
              "      <td>0.838927</td>\n",
              "      <td>0.738077</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c79ab3f9-e181-4a6b-8788-04033beb5e67')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c79ab3f9-e181-4a6b-8788-04033beb5e67 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c79ab3f9-e181-4a6b-8788-04033beb5e67');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-861cea44-94ee-43ee-bbdc-9cb666b137f5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-861cea44-94ee-43ee-bbdc-9cb666b137f5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-861cea44-94ee-43ee-bbdc-9cb666b137f5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "submit",
              "summary": "{\n  \"name\": \"submit\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50000,\n        \"samples\": [\n          \"TEST_33553\",\n          \"TEST_09427\",\n          \"TEST_00199\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fake\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24796196271424736,\n        \"min\": 1.4672237036439384e-10,\n        \"max\": 1.0,\n        \"num_unique_values\": 45030,\n        \"samples\": [\n          0.9502809643745422,\n          0.19116118550300598,\n          0.9884900450706482\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"real\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.26195311049202147,\n        \"min\": 1.1913262598639562e-09,\n        \"max\": 1.0,\n        \"num_unique_values\": 48050,\n        \"samples\": [\n          0.9931854009628296,\n          0.3394998610019684,\n          0.47401341795921326\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Distribution of Fake\")\n",
        "plt.hist(submit[\"fake\"], bins=20)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Distribution of Real\")\n",
        "plt.hist(submit[\"real\"], bins=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XYsUmtuX0UDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Et90yfJb8Qlv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}